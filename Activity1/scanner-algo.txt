PLCC token scanning algorithm details
-------------------------------------

Both token and skip matches, as given in the lexical specification,
are attempted in the exact order that the specifications appear in
the PLCC lexical specification section.

Matches are made following Java regular expression rules, but never
cross line boundaries.

A completed match is never an empty string.

Matches are always anchored at the current start of the input stream.
As the scanner runs through all the specifications, here is what
happens.

    Matching characters from the input stream starts with an empty
    token *candidate*.

    When a skip specification matches the start of the input stream:

        If there is no token candidate, the matched characters are
        consumed from the input stream, and lexical processing
        starts afresh (at the beginning) without adding any tokens
        to the output token stream.

        If there is already a non-empty token candidate (because
        some skip rules appear after token rules), the skip match
        is completely ignored.

    When a token specification matches the input stream:

        If the matched string has a length *greater* than that of
        the current candidate, then the candidate is replaced by
        this match, and matching continues. Otherwise the candidate
        is left unchanged, and matching continues.

The above approach is called "first longest match" because the
rule above implies that, if two or more (longest) token matches
have the same length, only the first is kept.

Once all of the token specifications have been examined:

    If the token candidate is nonempty, that token is added to the
    output token stream, the matched characters are consumed from
    the input stream, and lexical processing starts afresh. If the
    token candidate is empty and the input stream is not at
    end-of-file, an error "token" is added to the output token
    stream containing the first character in the input stream, that
    character is consumed, and token processing starts afresh.
    Otherwise an end-of-file "token" is added to the output token
    stream.

    The scanner does not actually emit the EOF token in a way that
    the parser can detect it.

When entering input from the keyboard, type ctrl-D to insert an EOF
character.

